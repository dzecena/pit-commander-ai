# ğŸ GR Cup Analytics - Complete Setup Guide

**Get your real Toyota GR Cup data and start analyzing!**

## ğŸ“ **File Organization (IMPORTANT!)**

### **Track Maps (PDF Format)**
**Put in:** `Track Maps/`
```
Track Maps/
â”œâ”€â”€ barber-motorsports-park-map.pdf
â”œâ”€â”€ circuit-of-the-americas-map.pdf
â”œâ”€â”€ indianapolis-map.pdf
â”œâ”€â”€ road-america-map.pdf
â”œâ”€â”€ sebring-map.pdf
â”œâ”€â”€ sonoma-map.pdf
â””â”€â”€ virginia-international-raceway-map.pdf
```

### **Data Files (ZIP Format)**
**Put in:** `data/raw/`
```
data/raw/
â”œâ”€â”€ barber-motorsports-park.zip
â”œâ”€â”€ circuit-of-the-americas.zip
â”œâ”€â”€ indianapolis.zip
â”œâ”€â”€ road-america.zip
â”œâ”€â”€ sebring.zip
â”œâ”€â”€ sonoma.zip
â””â”€â”€ virginia-international-raceway.zip
```

## ğŸš€ **Quick Start (3 Methods)**

### **Method 1: Automatic Download (Recommended)**
```bash
# Download all data files automatically
python scripts/download_data.py
```

### **Method 2: Manual Download**
1. Visit: https://trddev.com/hackathon-2025/Data files Order
2. Download each ZIP file
3. Save to `data/raw/` folder

### **Method 3: Command Line**
```powershell
# Windows PowerShell
New-Item -ItemType Directory -Force -Path "data/raw"

# Download each file
Invoke-WebRequest -Uri "https://trddev.com/hackathon-2025/barber-motorsports-park.zip" -OutFile "data/raw/barber-motorsports-park.zip"
Invoke-WebRequest -Uri "https://trddev.com/hackathon-2025/circuit-of-the-americas.zip" -OutFile "data/raw/circuit-of-the-americas.zip"
Invoke-WebRequest -Uri "https://trddev.com/hackathon-2025/indianapolis.zip" -OutFile "data/raw/indianapolis.zip"
Invoke-WebRequest -Uri "https://trddev.com/hackathon-2025/road-america.zip" -OutFile "data/raw/road-america.zip"
Invoke-WebRequest -Uri "https://trddev.com/hackathon-2025/sebring.zip" -OutFile "data/raw/sebring.zip"
Invoke-WebRequest -Uri "https://trddev.com/hackathon-2025/sonoma.zip" -OutFile "data/raw/sonoma.zip"
Invoke-WebRequest -Uri "https://trddev.com/hackathon-2025/virginia-international-raceway.zip" -OutFile "data/raw/virginia-international-raceway.zip"
```

## ğŸ”„ **Processing Pipeline**

### **Step 1: Extract and Process Data**
```bash
# Extract ZIP files and clean data
python scripts/process_real_data.py
```

**What this does:**
- âœ… Extracts all ZIP files to `data/extracted/`
- âœ… Identifies telemetry, lap times, sector data
- âœ… Cleans data (fixes lap errors, timestamps)
- âœ… Standardizes formats
- âœ… Generates quality reports

### **Step 2: Extract PDF Data (If Needed)**
```bash
# Extract data from PDF files
python scripts/extract_pdf_data.py
```

**What this does:**
- âœ… Finds PDF files in Track Maps/ and data folders
- âœ… Extracts tables from PDFs
- âœ… Converts to CSV format
- âœ… Maps sector data (S1.a â†’ IM1a, etc.)

### **Step 3: Train ML Model**
```bash
# Train model with real GR Cup data
python scripts/train_model.py
```

**What this does:**
- âœ… Loads all cleaned track data
- âœ… Engineers features for tire degradation
- âœ… Trains ML model (target: RÂ² > 0.95)
- âœ… Saves model artifacts
- âœ… Generates performance reports

### **Step 4: Test System**
```bash
# Test predictions with real data
python demo/race_demo.py
```

**What this does:**
- âœ… Simulates race scenarios
- âœ… Shows real-time predictions
- âœ… Demonstrates pit strategy
- âœ… Compares tracks

### **Step 5: Start API Server**
```bash
# Start the prediction API
uvicorn src.api.main:app --reload --port 8000
```

## ğŸ“Š **Expected Data Structure**

After processing, you'll have:

```
data/
â”œâ”€â”€ raw/                          # Your downloaded ZIP files
â”‚   â”œâ”€â”€ barber-motorsports-park.zip
â”‚   â”œâ”€â”€ circuit-of-the-americas.zip
â”‚   â””â”€â”€ ...
â”œâ”€â”€ extracted/                    # Auto-extracted from ZIPs
â”‚   â”œâ”€â”€ barber-motorsports-park/
â”‚   â”‚   â”œâ”€â”€ telemetry_data.csv
â”‚   â”‚   â”œâ”€â”€ lap_times.csv
â”‚   â”‚   â”œâ”€â”€ AnalysisEnduranceWithSections.csv
â”‚   â”‚   â””â”€â”€ results.csv
â”‚   â””â”€â”€ ...
â”œâ”€â”€ cleaned/                      # Processed and cleaned
â”‚   â”œâ”€â”€ BMP_telemetry_clean.csv
â”‚   â”œâ”€â”€ BMP_cleaning_stats.json
â”‚   â””â”€â”€ ...
â””â”€â”€ extracted_from_pdf/           # From PDF extraction
    â”œâ”€â”€ track_map_data.csv
    â””â”€â”€ ...
```

## ğŸ¯ **Key Data We're Looking For**

### **Priority 1: Telemetry Data**
- Time, Speed, RPM, Throttle, Brake, Steering, Gear, Lap
- This gives us the most ML value

### **Priority 2: Sector Analysis ("Analysis with Sections")**
- 6-sector timing: IM1a, IM1, IM2a, IM2, IM3a, FL
- Maps to track sectors: S1.a, S1.b, S2.a, S2.b, S3.a, S3.b

### **Priority 3: Lap Times**
- Lap number, lap time, sector splits
- For validation and comparison

## ğŸ” **Data Quality Checks**

Our system automatically handles:
- âœ… **Lap errors** (32768 values) â†’ Fixed using timestamp gaps
- âœ… **Vehicle IDs** (GR86-chassis-carnum) â†’ Parsed correctly
- âœ… **Timestamp drift** â†’ Uses meta_time over timestamp
- âœ… **Missing data** â†’ Intelligent fallbacks
- âœ… **Format variations** â†’ Standardizes column names

## ğŸ“ˆ **Expected Results**

With real GR Cup data:

### **Model Performance:**
- RÂ² > 0.95 (better than sample data)
- RMSE < 0.3 seconds
- Real tire degradation patterns

### **Track Insights:**
- Actual tire wear rates per track
- Real sector performance differences
- Genuine pit strategy opportunities

### **Business Value:**
- Predictions based on real race conditions
- Strategy recommendations from actual data
- Competitive advantage using historical performance

## ğŸ†˜ **Troubleshooting**

### **Download Issues:**
```bash
# Check if files downloaded correctly
ls -la data/raw/
```
- Files should be >50MB each
- Total size ~700MB-1GB

### **Extraction Issues:**
```bash
# Check extracted files
python scripts/simple_pdf_extractor.py
```
- Shows what files were found
- Identifies data types

### **Processing Issues:**
```bash
# Check logs for errors
python scripts/process_real_data.py
```
- Look for error messages
- Check data quality reports

### **Model Training Issues:**
```bash
# Validate data before training
python -c "
import pandas as pd
df = pd.read_csv('data/cleaned/VIR_telemetry_clean.csv')
print(f'Shape: {df.shape}')
print(f'Columns: {list(df.columns)}')
"
```

## âœ… **Success Checklist**

- [ ] All 7 ZIP files downloaded to `data/raw/`
- [ ] Track maps (if available) in `Track Maps/`
- [ ] ZIP files extract without errors
- [ ] Telemetry data found and cleaned
- [ ] Sector data (6 sectors) identified
- [ ] Model trains with RÂ² > 0.9
- [ ] Demo shows realistic predictions
- [ ] API server starts successfully

## ğŸ† **Final Validation**

You'll know everything is working when:
1. **Data loads cleanly** - No extraction errors
2. **Model performs well** - RÂ² > 0.9, reasonable predictions
3. **Predictions make sense** - Lap times in expected range
4. **Track differences show** - Different degradation per track
5. **Sector analysis works** - 6 sectors with realistic times

## ğŸš€ **Ready for Competition!**

Once everything is working:
- âœ… Real GR Cup data processed
- âœ… ML model trained on actual race data
- âœ… API serving live predictions
- âœ… Sector-level tire strategy
- âœ… Multi-track comparison
- âœ… Production-ready system

---

**You now have a complete race analytics system powered by real Toyota GR Cup data! ğŸ**

*This is the competitive advantage - real data, real insights, real strategy.*