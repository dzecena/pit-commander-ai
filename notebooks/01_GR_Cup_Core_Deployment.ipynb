{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ğŸ GR Cup Analytics - Core Deployment Notebook\n",
    "\n",
    "This notebook provides a complete, interactive deployment of the GR Cup Analytics platform.\n",
    "\n",
    "## What This Notebook Does:\n",
    "- âœ… Sets up the complete GR Cup analytics environment\n",
    "- âœ… Processes all 7 track telemetry datasets\n",
    "- âœ… Deploys live AWS dashboard\n",
    "- âœ… Creates baseline performance metrics\n",
    "- âœ… Validates deployment and data quality\n",
    "\n",
    "## Prerequisites:\n",
    "- AWS CLI configured with credentials\n",
    "- Node.js and npm installed\n",
    "- Python 3.9+ with required packages\n",
    "- Serverless Framework installed\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“‹ Step 1: Environment Setup and Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "import sys\n",
    "import subprocess\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import json\n",
    "import boto3\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"ğŸ GR Cup Analytics - Core Deployment\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Python Version: {sys.version}\")\n",
    "print(f\"Pandas Version: {pd.__version__}\")\n",
    "print(f\"NumPy Version: {np.__version__}\")\n",
    "\n",
    "# Check AWS credentials\n",
    "try:\n",
    "    sts = boto3.client('sts')\n",
    "    identity = sts.get_caller_identity()\n",
    "    print(f\"âœ… AWS Account: {identity['Account']}\")\n",
    "    print(f\"âœ… AWS User: {identity['Arn'].split('/')[-1]}\")\n",
    "except Exception as e:\n",
    "    print(f\"âŒ AWS credentials not configured: {e}\")\n",
    "    print(\"Please run: aws configure\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“Š Step 2: Data Processing and Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Import our data processing modules\n",
    "sys.path.append(str(Path.cwd()))\n",
    "from src.data_processing.data_cleaner import GRCupDataCleaner\n",
    "\n",
    "# Define all GR Cup tracks\n",
    "TRACKS = {\n",
    "    'BMP': 'Barber Motorsports Park',\n",
    "    'COTA': 'Circuit of the Americas',\n",
    "    'VIR': 'Virginia International Raceway',\n",
    "    'SEB': 'Sebring International Raceway',\n",
    "    'SON': 'Sonoma Raceway',\n",
    "    'RA': 'Road America',\n",
    "    'INDY': 'Indianapolis Motor Speedway'\n",
    "}\n",
    "\n",
    "print(\"ğŸï¸ Processing telemetry data for all 7 GR Cup tracks...\")\n",
    "print()\n",
    "\n",
    "processing_results = {}\n",
    "\n",
    "for track_id, track_name in TRACKS.items():\n",
    "    print(f\"ğŸ“Š Processing {track_id}: {track_name}\")\n",
    "    \n",
    "    # Check if raw data exists\n",
    "    raw_data_path = f\"data/extracted/{track_name.lower().replace(' ', '-')}/{track_id}_telemetry.csv\"\n",
    "    \n",
    "    if Path(raw_data_path).exists():\n",
    "        try:\n",
    "            # Initialize cleaner\n",
    "            cleaner = GRCupDataCleaner(track_id)\n",
    "            \n",
    "            # Clean the data\n",
    "            cleaned_df = cleaner.clean_telemetry(raw_data_path)\n",
    "            \n",
    "            # Store results\n",
    "            processing_results[track_id] = {\n",
    "                'status': 'success',\n",
    "                'records_processed': len(cleaned_df),\n",
    "                'unique_drivers': cleaned_df['vehicle_id'].nunique(),\n",
    "                'total_laps': cleaned_df['lap'].nunique(),\n",
    "                'cleaning_stats': cleaner.cleaning_stats\n",
    "            }\n",
    "            \n",
    "            print(f\"  âœ… Processed {len(cleaned_df):,} records\")\n",
    "            print(f\"  ğŸï¸ {cleaned_df['vehicle_id'].nunique()} drivers, {cleaned_df['lap'].nunique()} laps\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            processing_results[track_id] = {\n",
    "                'status': 'error',\n",
    "                'error': str(e)\n",
    "            }\n",
    "            print(f\"  âŒ Error: {e}\")\n",
    "    else:\n",
    "        processing_results[track_id] = {\n",
    "            'status': 'no_data',\n",
    "            'message': f'Raw data not found at {raw_data_path}'\n",
    "        }\n",
    "        print(f\"  âš ï¸ No raw data found\")\n",
    "    \n",
    "    print()\n",
    "\n",
    "# Summary\n",
    "successful_tracks = [t for t, r in processing_results.items() if r['status'] == 'success']\n",
    "print(f\"ğŸ“ˆ Data Processing Summary:\")\n",
    "print(f\"âœ… Successfully processed: {len(successful_tracks)} tracks\")\n",
    "print(f\"ğŸ“Š Tracks ready for analysis: {', '.join(successful_tracks)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸš€ Step 3: AWS Infrastructure Deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "import os\n",
    "\n",
    "print(\"ğŸš€ Deploying AWS infrastructure...\")\n",
    "print()\n",
    "\n",
    "# Check if Serverless Framework is installed\n",
    "try:\n",
    "    result = subprocess.run(['serverless', '--version'], capture_output=True, text=True, cwd='aws_deployment')\n",
    "    print(f\"âœ… Serverless Framework: {result.stdout.strip()}\")\n",
    "except FileNotFoundError:\n",
    "    print(\"âŒ Serverless Framework not found. Installing...\")\n",
    "    subprocess.run(['npm', 'install', '-g', 'serverless'], check=True)\n",
    "    print(\"âœ… Serverless Framework installed\")\n",
    "\n",
    "# Install deployment dependencies\n",
    "print(\"ğŸ“¦ Installing deployment dependencies...\")\n",
    "subprocess.run(['npm', 'install'], cwd='aws_deployment', check=True)\n",
    "print(\"âœ… Dependencies installed\")\n",
    "\n",
    "# Deploy to AWS\n",
    "print(\"ğŸŒ Deploying to AWS (this may take 2-3 minutes)...\")\n",
    "try:\n",
    "    deploy_result = subprocess.run([\n",
    "        'serverless', 'deploy', \n",
    "        '--stage', 'dev', \n",
    "        '--region', 'us-east-1'\n",
    "    ], capture_output=True, text=True, cwd='aws_deployment', timeout=300)\n",
    "    \n",
    "    if deploy_result.returncode == 0:\n",
    "        print(\"âœ… AWS deployment successful!\")\n",
    "        \n",
    "        # Extract API URL from output\n",
    "        output_lines = deploy_result.stdout.split('\\n')\n",
    "        api_url = None\n",
    "        for line in output_lines:\n",
    "            if 'execute-api' in line and 'amazonaws.com' in line:\n",
    "                api_url = line.split()[-1]\n",
    "                break\n",
    "        \n",
    "        if api_url:\n",
    "            dashboard_url = f\"{api_url}/dashboard\"\n",
    "            print(f\"ğŸŒ API URL: {api_url}\")\n",
    "            print(f\"ğŸ“Š Dashboard URL: {dashboard_url}\")\n",
    "            \n",
    "            # Save deployment info\n",
    "            deployment_info = {\n",
    "                'deployment_date': datetime.now().isoformat(),\n",
    "                'api_url': api_url,\n",
    "                'dashboard_url': dashboard_url,\n",
    "                'stage': 'dev',\n",
    "                'region': 'us-east-1'\n",
    "            }\n",
    "            \n",
    "            with open('deployment_info.json', 'w') as f:\n",
    "                json.dump(deployment_info, f, indent=2)\n",
    "            \n",
    "            print(\"ğŸ’¾ Deployment info saved to deployment_info.json\")\n",
    "        else:\n",
    "            print(\"âš ï¸ Could not extract API URL from deployment output\")\n",
    "    else:\n",
    "        print(f\"âŒ Deployment failed: {deploy_result.stderr}\")\n",
    "        \n",
    "except subprocess.TimeoutExpired:\n",
    "    print(\"â° Deployment timed out. Check AWS Console for status.\")\n",
    "except Exception as e:\n",
    "    print(f\"âŒ Deployment error: {e}\")"
   ]
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“¤ Step 4: Upload Telemetry Data to AWS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "print(\"ğŸ“¤ Uploading processed telemetry data to AWS S3...\")\n",
    "print()\n",
    "\n",
    "s3_client = boto3.client('s3')\n",
    "bucket_name = \"gr-cup-data-dev-us-east-1-v2\"\n",
    "\n",
    "upload_results = {}\n",
    "\n",
    "for track_id in successful_tracks:\n",
    "    cleaned_file = f\"data/cleaned/{track_id}_telemetry_clean.csv\"\n",
    "    \n",
    "    if Path(cleaned_file).exists():\n",
    "        try:\n",
    "            s3_key = f\"processed-telemetry/{track_id}_telemetry_clean.csv\"\n",
    "            \n",
    "            print(f\"ğŸ“Š Uploading {track_id} telemetry...\")\n",
    "            s3_client.upload_file(\n",
    "                cleaned_file,\n",
    "                bucket_name,\n",
    "                s3_key,\n",
    "                ExtraArgs={'ContentType': 'text/csv'}\n",
    "            )\n",
    "            \n",
    "            upload_results[track_id] = {\n",
    "                'status': 'success',\n",
    "                's3_location': f's3://{bucket_name}/{s3_key}'\n",
    "            }\n",
    "            \n",
    "            print(f\"  âœ… Uploaded to s3://{bucket_name}/{s3_key}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            upload_results[track_id] = {\n",
    "                'status': 'error',\n",
    "                'error': str(e)\n",
    "            }\n",
    "            print(f\"  âŒ Upload failed: {e}\")\n",
    "    else:\n",
    "        print(f\"  âš ï¸ Cleaned data file not found for {track_id}\")\n",
    "\n",
    "successful_uploads = [t for t, r in upload_results.items() if r['status'] == 'success']\n",
    "print(f\"\\nğŸ“ˆ Upload Summary:\")\n",
    "print(f\"âœ… Successfully uploaded: {len(successful_uploads)} tracks\")\n",
    "print(f\"ğŸ“Š Data available in dashboard: {', '.join(successful_uploads)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ¯ Step 5: Generate Baseline Performance Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "from scripts.new_data_processor import NewDataProcessor\n",
    "\n",
    "print(\"ğŸ¯ Generating baseline performance metrics...\")\n",
    "print()\n",
    "\n",
    "processor = NewDataProcessor()\n",
    "baseline_results = {}\n",
    "\n",
    "for track_id in successful_tracks:\n",
    "    print(f\"ğŸ“Š Creating baseline for {track_id}: {TRACKS[track_id]}\")\n",
    "    \n",
    "    try:\n",
    "        # Load cleaned data\n",
    "        cleaned_file = f\"data/cleaned/{track_id}_telemetry_clean.csv\"\n",
    "        df = pd.read_csv(cleaned_file)\n",
    "        \n",
    "        # Create baseline\n",
    "        baseline = processor.load_or_create_baseline(track_id)\n",
    "        updated_baseline = processor.update_baseline_with_new_data(baseline, df)\n",
    "        \n",
    "        # Save baseline\n",
    "        baseline_file = f\"data/baselines/{track_id}_baseline_metrics.json\"\n",
    "        Path(\"data/baselines\").mkdir(exist_ok=True)\n",
    "        \n",
    "        with open(baseline_file, 'w') as f:\n",
    "            json.dump(updated_baseline, f, indent=2)\n",
    "        \n",
    "        baseline_results[track_id] = {\n",
    "            'status': 'success',\n",
    "            'total_drivers': updated_baseline['total_drivers'],\n",
    "            'field_avg_speed': round(updated_baseline['overall_benchmarks']['field_avg_speed'], 1),\n",
    "            'field_max_speed': round(updated_baseline['overall_benchmarks']['field_max_speed'], 1)\n",
    "        }\n",
    "        \n",
    "        print(f\"  âœ… Baseline created\")\n",
    "        print(f\"  ğŸï¸ {updated_baseline['total_drivers']} drivers analyzed\")\n",
    "        print(f\"  ğŸš€ Field avg speed: {updated_baseline['overall_benchmarks']['field_avg_speed']:.1f} mph\")\n",
    "        print(f\"  ğŸ Field max speed: {updated_baseline['overall_benchmarks']['field_max_speed']:.1f} mph\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        baseline_results[track_id] = {\n",
    "            'status': 'error',\n",
    "            'error': str(e)\n",
    "        }\n",
    "        print(f\"  âŒ Error creating baseline: {e}\")\n",
    "    \n",
    "    print()\n",
    "\n",
    "successful_baselines = [t for t, r in baseline_results.items() if r['status'] == 'success']\n",
    "print(f\"ğŸ“ˆ Baseline Generation Summary:\")\n",
    "print(f\"âœ… Successfully created: {len(successful_baselines)} baselines\")\n",
    "print(f\"ğŸ“Š Tracks with performance benchmarks: {', '.join(successful_baselines)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## âœ… Step 6: Deployment Validation and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "import requests\n",
    "import time\n",
    "\n",
    "print(\"âœ… Validating deployment and testing endpoints...\")\n",
    "print()\n",
    "\n",
    "# Load deployment info\n",
    "try:\n",
    "    with open('deployment_info.json', 'r') as f:\n",
    "        deployment_info = json.load(f)\n",
    "    \n",
    "    api_url = deployment_info['api_url']\n",
    "    dashboard_url = deployment_info['dashboard_url']\n",
    "    \n",
    "    print(f\"ğŸŒ Testing API at: {api_url}\")\n",
    "    \n",
    "    # Test API health\n",
    "    try:\n",
    "        response = requests.get(f\"{api_url}/health\", timeout=10)\n",
    "        if response.status_code == 200:\n",
    "            print(\"âœ… API health check passed\")\n",
    "        else:\n",
    "            print(f\"âš ï¸ API health check returned status {response.status_code}\")\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ API health check failed: {e}\")\n",
    "    \n",
    "    # Test tracks endpoint\n",
    "    try:\n",
    "        response = requests.get(f\"{api_url}/tracks\", timeout=10)\n",
    "        if response.status_code == 200:\n",
    "            tracks_data = response.json()\n",
    "            print(f\"âœ… Tracks endpoint working - {tracks_data['total_tracks']} tracks available\")\n",
    "        else:\n",
    "            print(f\"âš ï¸ Tracks endpoint returned status {response.status_code}\")\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Tracks endpoint test failed: {e}\")\n",
    "    \n",
    "    # Test driver data for first successful track\n",
    "    if successful_uploads:\n",
    "        test_track = successful_uploads[0]\n",
    "        try:\n",
    "            response = requests.get(f\"{api_url}/drivers/{test_track}\", timeout=15)\n",
    "            if response.status_code == 200:\n",
    "                driver_data = response.json()\n",
    "                drivers_count = len(driver_data['telemetry_data']['drivers'])\n",
    "                print(f\"âœ… Driver data endpoint working - {drivers_count} drivers found for {test_track}\")\n",
    "            else:\n",
    "                print(f\"âš ï¸ Driver data endpoint returned status {response.status_code}\")\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ Driver data endpoint test failed: {e}\")\n",
    "    \n",
    "    print()\n",
    "    print(\"ğŸ¯ Deployment Validation Complete!\")\n",
    "    print(\"=\" * 50)\n",
    "    print(f\"ğŸŒ Live Dashboard: {dashboard_url}\")\n",
    "    print(f\"ğŸ“Š API Endpoint: {api_url}\")\n",
    "    print(f\"ğŸ“ˆ Tracks Available: {len(successful_uploads)}\")\n",
    "    print(f\"ğŸï¸ Total Drivers: {sum(r.get('total_drivers', 0) for r in baseline_results.values() if r['status'] == 'success')}\")\n",
    "    \n",
    "except FileNotFoundError:\n",
    "    print(\"âŒ Deployment info not found. Deployment may have failed.\")\n",
    "except Exception as e:\n",
    "    print(f\"âŒ Validation error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“‹ Step 7: Deployment Summary and Next Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "print(\"ğŸ“‹ GR Cup Analytics - Deployment Summary\")\n",
    "print(\"=\" * 50)\n",
    "print()\n",
    "\n",
    "# Create comprehensive summary\n",
    "summary = {\n",
    "    'deployment_date': datetime.now().isoformat(),\n",
    "    'data_processing': processing_results,\n",
    "    'aws_uploads': upload_results,\n",
    "    'baseline_metrics': baseline_results,\n",
    "    'deployment_info': deployment_info if 'deployment_info' in locals() else None\n",
    "}\n",
    "\n",
    "# Save complete summary\n",
    "with open('deployment_summary.json', 'w') as f:\n",
    "    json.dump(summary, f, indent=2, default=str)\n",
    "\n",
    "print(\"ğŸ“Š Data Processing Results:\")\n",
    "for track_id, result in processing_results.items():\n",
    "    status_icon = \"âœ…\" if result['status'] == 'success' else \"âŒ\" if result['status'] == 'error' else \"âš ï¸\"\n",
    "    print(f\"  {status_icon} {track_id}: {result['status']}\")\n",
    "\n",
    "print()\n",
    "print(\"ğŸŒ AWS Deployment:\")\n",
    "if 'deployment_info' in locals():\n",
    "    print(f\"  âœ… Status: Successful\")\n",
    "    print(f\"  ğŸŒ Dashboard: {deployment_info['dashboard_url']}\")\n",
    "    print(f\"  ğŸ“Š API: {deployment_info['api_url']}\")\n",
    "else:\n",
    "    print(f\"  âŒ Status: Failed or incomplete\")\n",
    "\n",
    "print()\n",
    "print(\"ğŸ“ˆ Performance Baselines:\")\n",
    "for track_id, result in baseline_results.items():\n",
    "    if result['status'] == 'success':\n",
    "        print(f\"  âœ… {track_id}: {result['total_drivers']} drivers, avg {result['field_avg_speed']} mph\")\n",
    "\n",
    "print()\n",
    "print(\"ğŸ¯ Next Steps:\")\n",
    "print(\"1. ğŸŒ Visit the dashboard to explore driver analytics\")\n",
    "print(\"2. ğŸ“Š Use the API endpoints for custom integrations\")\n",
    "print(\"3. ğŸ“¤ Upload new telemetry data using the additional data notebook\")\n",
    "print(\"4. ğŸï¸ Share dashboard with drivers and teams for performance analysis\")\n",
    "\n",
    "print()\n",
    "print(\"ğŸ’¾ All deployment details saved to:\")\n",
    "print(\"  - deployment_info.json (AWS endpoints)\")\n",
    "print(\"  - deployment_summary.json (complete summary)\")\n",
    "print(\"  - data/baselines/ (performance benchmarks)\")\n",
    "\n",
    "print()\n",
    "print(\"ğŸ GR Cup Analytics deployment complete! ğŸ\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}