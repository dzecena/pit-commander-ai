{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üèéÔ∏è GR Cup Analytics - Additional Data Processing\n",
    "\n",
    "This notebook handles new telemetry data integration with existing baselines.\n",
    "\n",
    "## What This Notebook Does:\n",
    "- ‚úÖ Processes new telemetry sessions\n",
    "- ‚úÖ Compares new data with existing baselines\n",
    "- ‚úÖ Updates performance benchmarks\n",
    "- ‚úÖ Generates driver improvement reports\n",
    "- ‚úÖ Uploads new data to live dashboard\n",
    "\n",
    "## Use Cases:\n",
    "- Adding new practice/qualifying/race sessions\n",
    "- Integrating new driver data\n",
    "- Updating performance baselines\n",
    "- Generating progress reports\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìã Step 1: Setup and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import json\n",
    "import boto3\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Add project root to path\n",
    "sys.path.append(str(Path.cwd()))\n",
    "\n",
    "from scripts.new_data_processor import NewDataProcessor\n",
    "from src.data_processing.data_cleaner import GRCupDataCleaner\n",
    "\n",
    "print(\"üèéÔ∏è GR Cup Analytics - Additional Data Processing\")\n",
    "print(\"=\" * 55)\n",
    "print(f\"Timestamp: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print()\n",
    "\n",
    "# Initialize processor\n",
    "processor = NewDataProcessor()\n",
    "\n",
    "# Check existing baselines\n",
    "baseline_dir = Path(\"data/baselines\")\n",
    "if baseline_dir.exists():\n",
    "    existing_baselines = list(baseline_dir.glob(\"*_baseline_metrics.json\"))\n",
    "    print(f\"üìä Found {len(existing_baselines)} existing baselines:\")\n",
    "    for baseline_file in existing_baselines:\n",
    "        track_id = baseline_file.stem.replace('_baseline_metrics', '')\n",
    "        print(f\"  ‚úÖ {track_id}\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No existing baselines found. Run core deployment notebook first.\")\n",
    "\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üì§ Step 2: Upload New Telemetry Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration for new data file\n",
    "NEW_DATA_FILE = \"path/to/your/new/telemetry.csv\"  # Update this path\n",
    "SESSION_TYPE = \"PRACTICE\"  # PRACTICE, QUALIFYING, or RACE\n",
    "SESSION_DATE = datetime.now().strftime(\"%Y%m%d\")\n",
    "\n",
    "print(\"üì§ New Telemetry Data Upload Configuration\")\n",
    "print(\"=\" * 45)\n",
    "print(f\"Data File: {NEW_DATA_FILE}\")\n",
    "print(f\"Session Type: {SESSION_TYPE}\")\n",
    "print(f\"Session Date: {SESSION_DATE}\")\n",
    "print()\n",
    "\n",
    "# Check if file exists\n",
    "if Path(NEW_DATA_FILE).exists():\n",
    "    print(\"‚úÖ New data file found\")\n",
    "    \n",
    "    # Preview the data\n",
    "    preview_df = pd.read_csv(NEW_DATA_FILE, nrows=5)\n",
    "    print(f\"üìä Data preview ({len(preview_df)} rows shown):\")\n",
    "    print(preview_df.head())\n",
    "    print()\n",
    "    \n",
    "    # Check data format\n",
    "    required_columns = [\n",
    "        'vehicle_id', 'timestamp', 'lap', 'Speed', 'pbrake_f', \n",
    "        'ath', 'Steering_Angle', 'accx_can', 'accy_can', 'nmotor', 'Gear'\n",
    "    ]\n",
    "    \n",
    "    missing_columns = [col for col in required_columns if col not in preview_df.columns]\n",
    "    if missing_columns:\n",
    "        print(f\"‚ùå Missing required columns: {missing_columns}\")\n",
    "        print(\"Please ensure your data file has all required columns.\")\n",
    "    else:\n",
    "        print(\"‚úÖ Data format validation passed\")\n",
    "        \n",
    "        # Get basic stats\n",
    "        full_df = pd.read_csv(NEW_DATA_FILE)\n",
    "        print(f\"üìà Data Statistics:\")\n",
    "        print(f\"  Total Records: {len(full_df):,}\")\n",
    "        print(f\"  Unique Drivers: {full_df['vehicle_id'].nunique()}\")\n",
    "        print(f\"  Total Laps: {full_df['lap'].nunique()}\")\n",
    "        print(f\"  Track ID: {full_df['track_id'].iloc[0] if 'track_id' in full_df.columns else 'Not specified'}\")\n",
    "        \n",
    "else:\n",
    "    print(f\"‚ùå Data file not found: {NEW_DATA_FILE}\")\n",
    "    print(\"Please update the NEW_DATA_FILE path above to point to your telemetry CSV file.\")\n",
    "    print()\n",
    "    print(\"üìã Required CSV format:\")\n",
    "    print(\"vehicle_id,timestamp,meta_time,lap,Speed,pbrake_f,ath,Steering_Angle,accx_can,accy_can,nmotor,Gear,track_name,track_id\")\n",
    "    print(\"GR86-002-015,1761847091636,1761847091636,1,158.02,0.0,77.00,-0.16,-0.84,0.45,6900.42,5,Barber Motorsports Park,BMP\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}